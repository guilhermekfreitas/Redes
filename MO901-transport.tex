\chapter{Camada de Transporte}

É responsável pelo transporte fim-a-fim, por prover à camada de transporte uma comunicação lógica entre dois processos.
A camada de rede que fica abaixo é responsável por realizar a comunicação entre dois processos.
A de transporte, empregando a de rede faz a comunicação entre dois processos.

\section{Multiplexação}

Como vários processos podem rodar em um mesmo host, um dos papéis da camada de transporte é fazer a multiplexação das mensagens no emitente (para que elas compartilhem dos canais lógicos de comunicação) e demultiplexar no destinatário, remontando as mensagens do processo emitente e entregando-as ao processo destino.

Para tal, os dados a serem trocados são inicialmente quebrados em \emph{segmentos} que são enviados, através do serviço de entrega oferecido pela camada de rede.
O cabeçalho adicionado por tal segmento tem que tem, em particular, um identificador dos processos que se comunicam.

Neste ponto, os dois principais protocolos de transporte são distintos.

No UDP não há estabelecimento de conexão, então qualquer processo é unicamente identificado na Web através do endereço do seu hospedeiro e de um \emph{número de porta} único que é escolhido pelo processo.
Assim, o segmento enviado contém estes dois dados que permitem a demultiplexação.
Outro campo empregado é a porta de origem, que é usada na camada de aplicação como porta de destino para responder à mensagem.

Já no TCP, esta identificação não basta.
Ao iniciar uma conexão, um processo envia uma mensagem para um host + porta do servidor.
Ele, então, cria um socket local com uma porta associada, que é enviada.

A questão é que o servidor tem um socket (host + porta) que aceita todas requisições de conexão, iniciando-as.
Assim, estando ela estabelecida, as mensagens que chegam para o mesmo host + porta sem o bit SYN ligado, são direcionadas ao processo que é identificado por, além do host+porta destino, do host+porta do emissor.
Isto porque um mesmo host pode fazer requisições na mesma porta do servidor (digamos, a 80 de um servidor Web) e, além disto, hosts diferentes podem escolher uma mesma porta local.

Assim, ao receber um segmento, o TCP vai analizar host + porta de partida e host + porta de destino para fazer a demultiplexação e entregara a mensagem ao processo correto.

\section{UDP}

Sua principal característica é não ter-se ideia de conexão. 
Assim, se adiciona às mensagens um cabeçalho simples e se envia elas ao destinatário.
As informações do cabeçalho são as essenciais: portas de saída e destino, tamanho do pacote (incluindo o cabeçalho) e um checksum.

As portas são usadas para entregar as mensagens ao processo certo e são o que fazem que não se use diretamente um pacote IP para realizar estas trocas de mensagens sem o overload de um protocolo de transporte.

O checksum é realizado sobre o segmento e também sobre parte do cabeçalho IP e consiste no complemento de 2 dos campos checados.
O destinatário então, checa se a soma de todos os campos, inclusive o checksum não contém bits 0.
Se houver problema, o UDP não lida com eles. Ele pode descartar a mensagem ou repassá-la ao processo junto a um warning.

As vantagens do UDP são relacionadas à sua simplicidade: cabeçalho curto (8 bytes), não gasta-se tempo com o estabelecimento de conexões e não se mantém estado, ou seja, não tem-se uma série de informações e buffers que devem ser mantidas associadas a cada socket, como no caso do TCP.
Outra grande vantagem é não ter-se as limitações de taxas de envio estipuladas pelo controle de congestionamento.
Por outro lado, a confiabilidade da comunicação e o tratamento de perdas deve ser feito pela aplicação.

\section{Transferência confiável de dados}

Esta seção constroi passo a passo um protocolo de comunicação confiável entre um emitente e um receptor.
Para tal, emprega-se uma série de mecanismos de checagem e controle que fazem com que a transmissão não-confiável (com perdas e/ou corrupção de pacotes) oferecida por uma camada inferior seja transformado num serviço confiável de entrega de dados, fornecido à camada superior.

Inicialmente cita-se o mecanismos chamados protocolos \emph{Automatica Repeat reQuest} ou \emph{ARQ}.
Eles contém, além das mensagens enviadas, mensagens de controle enviadas pelo receptor.
São o \emph{ACK}, que indica que a mensagem chegou corretamente e \emph{NACK}, que indica que a mensagem chegou incorretamente.

Estes protocolos baseiam-se no \emph{sender feedback} e tem que se basear em alguma forma de detecção de erros (corrupção).
A grande questão deles é de como se lidar com as retransmissões. 
A primeira alternativa é o \emph{stop-and-wait}, onde o emissor não envia novas mensagens enquanto não recebe um ACK e reenvia a mesma mensagem enquanto receber NACKs.

A limitação desta abordagem é desconsiderar a possibilidade dos pacotes de controles serem corrompidos.
Quando isto ocorre, o emissor não sabe se deve enviar uma nova mensagem ou reenviar a anterior, fazendo com que o receptor não saiba se uma mensagem está sendo reenviada ou se é nova.
Assim, este protocolo não é suficiente pois não lida com pacotes replicados.

Para fazer esta distinção, então, é necessário usar \emph{números de sequência} para os pacotes, que mesmo sendo binários, permitem saber se o pacote é novo ou duplicado.
Assim o emitente está no estado de envio do pacote $0$, passa para obtenção do ACK para o pacote $0$, passa para envio do pacote $1$, recepção do ACK para o pacote $1$ o que fecha o ciclo.

O interessante desta nova abordagem é que os NACKs passam a não ser mais necessário, pois um ACK para a sequência $0$ enquanto aguarda-se um ACK para $1$, ou seja, um \emph{ACK duplicado}, significa que o $1$ não foi recebido corretamente.
Assim, adicionando o número de sequência aos ACKs passa a se ter somente uma mensagem de controle.

Ao levar-se em consideração a possibilidade de perdas de pacotes, tem-se outro problema que é como o emissor sabe se o pacote chegou corretamente, já que tanto ele pode se perder assim como o ACK a ele associado.
Para tal é necessário que se tenha uma reação que independa do recebimento de uma mensagem (de dados ou controle), que seja temporal.
Assim, estipula-se um valor de tempo após o envio e se ele for atingido sem que não se tenha um feedback, o pacote é reenviado.

Isto é implementado com um \emph{countdown timer}, ativado sempre que se envia uma mensagem (de controle ou não) e desativado sempre que uma resposta chega.
Quando ele ``estoura'', um nova contagem de tempo é iniciado para o pacote duplicado enviado.

Este protocolo que lida com duplicatas através de número de sequências binários e com perdas com timeouts é conhecido por \emph{alternanting-bit-protocol}.
E ele é capaz de fazer um transporte confiável entre dois hosts, lidando com perdas e corrupção de mensagens.

A questão é que nesta abordagem \emph{stop-and-wait} o tempo efetivo de uso do canal é bem reduzido.
Isto porque somente uma mensagem pode estar trafegando por ele e nenhuma outra será enviada antes que o ACK correspondente seja recebido.
Para lidar com esta limitação, deve-se agir de forma a permitir que várias mensagens sejam enviadas antes que uma confirmação chegue.
Como deve-se manter a consistência da entrega, estes protocolos são considerados como uma forma de fazer um pipeline deste protocolo descrito anteriormente.

Há aqui duas vertentes, que lidam de forma diferente com os pacotes ainda não confirmados: o \emph{Go-back-n} e o \emph{selective repeat}.

\subsection{Go-back-N}

Neste protocolo o emissor pode enviar até $N$ mensagens antes de receber alguma confirmação de entrega.
Assim, define-se uma \emph{janela de transmissão} de tamanho $N$ que contém um intervalo de números de sequência que podem ser empregados para envio imediato de segmentos.
Esta janela é limitada inferiormente pela \emph{base}, que é o número sucessor ao último número de sequência confirmado e superiormente por $base + n$.
Dentro deste intervalo há um índice que é o próximo número de sequência empregável, usado como número do próximo segmento a ser enviado.

Para lidar com perdas e corrupções emprega-se igualmente um temporizador.
Caso ele estoure, reenvia-se todas as mensagens ainda não confirmadas, ou seja, com número de sequência no intervalo $[base, nextseqnum]$.
A cada ACK recebido do pacote $x$, a base passa a ser $x+1$ e o temporizador é reiniciado se houver ainda algum pacote a ser confirmado. 
Nota-se então que os ACKs são cumulativos, ou seja, representam que todos pacotes antes de $x$ foram recebidos corretamente.

Da parte do receptor, ele mantém somente uma variável com o número do próximo pacote esperado.
Chegando ele, gera-se um ACK para este valor, este número é incrementado e o pacote repassado para a aplicação (a recepção é em ordem).
Qualquer pacote com número maior ou menor é descartado, mas o último ACK é reenviado, porque ele poderia ter se perdido.

\subsection{Selective Repeat}

Esta abordagem vem da limitação do GBN de reenviar todos pacotes ainda não confirmados na falta de um ACK com número de sequência da base.
Em redes com muitas perdas isto pode gerar um tráfego grande de pacotes duplicados. 
Além disto, pacotes que chegam em ordem diferente do envio são sumariamente descartados (e terão de ser reenviados).

No SR tem-se a janela do emissor e do receptor com números mínimos $send_base$ e $rcv_base$ e mesmo tamanho $N$.
O receptor irá receber qualquer pacote do intervalo e confirmá-los independentemente.
Quando o menor pacote ou ACK esperados chegam, os $base$ são incrementados e o temporizador (que é individual por pacote enviado) é parado.

A entrega ainda se dá em ordem, mas a recepção não. 
Assim, pacotes duplicados e novos devem ser diferenciados, fazendo com que o tamanho da janela tenha que ser ao máximo metade do range de número de sequência.
Isto garante que cada número dentro da janela só possa ser um novo pacote ou uma cópia.

\subsection{Método empregado pelo TCP}

O TCP emprega um híbrido das técnicas mostradas, tentando obter o melhor delas.
Inicialmente, o número de sequência máximo é muito alto $2^{32} -1$ e o tamanho da janela é no máximo $2^{16} -1$, dependendo do controle de fluxo e congestionamento.
Porém, este número de sequência não é o número do segmento, mas sim a quantidade de bytes já enviados.

Assim, o envio se dá gerando o segmento com o próximo valor, incrementando o este valor com o tamanho dos dados e iniciando um temporizador, 
caso nenhum já esteja em curso.
A confirmação se dá por ACKs que contém o próximo número de sequência esperado, são cumulativos e levam ao reinício do temporizador, caso algum segmento não esteja ainda confirmado.

Com o estouro do temporizador, reenvia-se o último segmento ainda não confirmado e o timer é reiniciado.
O tempo de espera é obtido estatísticamente mas, no caso de estouro do timer, é configurado para o \emph{dobro} do valor anterior.

Do lado do receptor, mantém-se o próximo byte esperado e um buffer, que armazena pacotes com números de sequências maiores, mas dentro da janela.
Ao receber o pacote esperado o TCP não responde imediatamente, aguardando $500ms$ ou a chegada do próximo pacote (gerando um ACK cumulativo de dois segmentos).

Ao receber um pacote ``futuro'', um ACK é gerado para o pacote esperado.
No lador emissor, 3 ACKs duplicados para um segmento fazem com que ele seja reenviado, mesmo que o timer não tenha estourado, mecanismo conhecido como \emph{fast retransmit}.
Neste mesmo caso, se o receptor obtiver o byte esperado, ele e todos os bytes seguintes recebidos são entregues à aplicação e um ACK cumulativo é gerado.

Assim, evita-se o máximo retransmissões desnecessárias e possível congestionamento, pois geram-se ACKs cumulativos, só se retransmite o último pacote esperado e o timeout é duplicado em caso de atraso maior, desde que não haja novos ACKs ou novos envios.

\subsubsection{Estipulação dos timeouts}

O cálculo dos valores que deve ser empregado pelos temporizadores é feito através de estimativas, baseadas em medições de \emph{Round Times Trips} reais.
Elas são obtidas através de uma amostragem dos RTTs de alguns segmentos de uma conexão, dentre os que não são retransmitidos.

Tem-se o valor estimado para o RTT $EstimatedRTT = (1 - \alpha) . EstimatedRTT + \alpha . SampleRTT$, que é uma amostragem que exponencialmente decresce a influência de medidas antigas.
Além dele, usa-se a variação do RTT $VarRTT = (1 - \beta) . VarRTT + \beta . | EstimatedRTT - SampleRTT|$, com o mesmo formato.

Define-se o valor de timeout como sendo $EstimatedRTT + 4 . VarRTT$ e recomenda-se $\alpha = 0.125$ e $\beta = 0.25$.
Idealmente, o timeout é algo superior ao RTT (para evitar retransmissões desnecessárias) mas não tanto a ponto do tempo de resposta a perdas ser longo demais.


\subsection{Controle de fluxo TCP}

Não foi definido anteriormente o tamanho da janela TCP, pois ela é variável.
Esta abordagem é necessária para evitar que o emissor envie dados a uma taxa superior à taxa que o TCP processa, armazena os dados no buffer de entrada e, principalmente, à velocidade em que a aplicação lê (e, assim, libera espaço) do buffer de entrada.

No início da conexão, o receptor aloca o buffer de entrada com um tamanho que é o máximo tamanho da janela.
Este valor é repassado ao emissor, e é o tamanho incial de sua janela de envio, ou seja, o máximo número de bytes enviados e ainda não confirmados.
A cada confirmação o receptor atualiza o tamanho da janela do emissor, com o espaço disponível naquele momento no buffer.

Um problema desta abordagem é quando o buffer do receptor fica cheio, o que faz com que o emissor pare de enviar.
Neste caso, não havendo dados no sentido contrário, a janela de envio não será atualizada, mesmo havendo espaço no buffer do receptor.
Para contornar isto, o protocolo estabele que o emissor deve enviar periodicamente uma mensagem mínima para obter o tamanho de buffer disponível no receptor.

\section{TCP}

\subsection{Segmento TCP}

Um segmento TCP contém um cabeçalho, com uma série de informações úteis para o fluxo entre os processos.

Os primeiros campos são as portas de partida e destino (16 bits cada), usadas para multiplexação (o endereço está no pacote IP).

Depois tem-se valores usados na entrega de dados, ou seja o número de sequência do segmento e o número do ACK (32 bits cada um).
Como já dito, os segmentos são numerados com o primeiro byte do fluxo que eles carregam e os ACKs contém o próximo byte esperado do emissor.
Vale dizer que a conexão é \emph{full-duplex}, ou seja, os dois são emissores e receptores.
Desta forma, os ACKs costumam ir \emph{piggybacked} em pacotes com dados, o que é percebido por um bit que denota se o campo ACK é válido.

Outro campo de 16 bits é usado no controle de fluxo e contém o espaço disponível na janela de recepção.
Com 16 bits tem-se também o checksum do pacote, e há 3 bits para indicar ações de gerenciamento da conexão: \emph{SYN, FIN, RST}.

Há outros campos pouco usados atualmente.
O \emph{PSH} é um bit que diz se os dados devem ser enviados imeditamente à aplicação.
Outro bit é o \emph{URG} indica que o campo \emph{urgent data point} (com 16 bits) contém um ponteiro para certo dado que deve ser entregue na aplicação com urgência.

Finalmente, há um campo extra de opções que contém dados se o campo de tamanho de cabeçalho (4 bits) indicar mais que 5, 
que dá o tamanho mínimo do cabeçalho TCP de 20 bytes.

Além do cabeçalho tem-se os dados trocados entre os processos, cuja quantidade é variável e limitada pelo \emph{Maximum segment size} ou \emph{MSS}.
Ele é tal que, junto ao tamanho dos cabeçalhos TCP e IP não seja maior que o \emph{maximum transmission unit} ou \emph{MTU},
que o tamanho máximo de um \emph{frame} da camada de enlace de dados.

Há também protocolos que obtém o \emph{MTU} para o caminho mais provável entre os dois hosts, com o claro objetivo de evitar ao máximo que o segmento TCP seja fragmentado em algum nó intermediário da rede.

\subsection{Gerenciamento das conexões}

A abertura de uma conexão TCP é feita através de três passos, sendo conhecida como \emph{three-way handshape}:
\paragraph{1} O cliente envia um segmento TCP sem dados, com o bit \emph{SYN} ativado e com um número de sequência aleatório.
\paragraph{2} O servidor aloca os buffers e variáveis para a conexão e responde com outro pacote sem dados. 
Ele tem o bit \emph{SYN} ativado, um número de sequência e o número de sequência do cliente incrementado no campo ACK.
Ele é uma confirmação do estabelecimento da conexão, sendo chamado de \emph{SYNACK}.
\paragraph{3} Recebendo este pacote, o cliente aloca buffers e variáveis e responde ao servidor com o campo ACK adequado e, possivelmente, com dados.
\paragraph{} 

Nota-se que o passo 2 pode ser perigoso, pois inúmeras conexões podem ser abertas sem serem usadas.
Este ataque é conhecido como \emph{syn flood} e causa negação de serviço, pois várias conexões são meio-abertas para nada.

Há uma modificação no TCP que evita tal ataque, empregando \emph{syn cookies}.
Nela, o servidor não cria a estrutura e responde com um número de sequência especial, calculado a partir dos endereços e uma chave secreta.
Se um cliente legítimo retornar um ACK, o servidor checa se o número de sequência é correto e inicializa a estrutura, que não é comprometida.

O fechamento de uma conexão TCP é feito com quatro passos:
\paragraph{1} Uma das partes envia um segmento com o bit \emph{FIN} ativado
\paragraph{2} A outra parte envia um ACK, desaloca recursos e envia um \emph{FIN}
\paragraph{3} A solicitante recebe o \emph{FIN} e envia um ACK
\paragraph{4} O solicitante aguarda por um tempo (estado \emph{TIMEWAIT}) antes de desalocar os recursos completamente

\paragraph{} Além destas possibilidades, há o uso do bit \emph{RST}. 
Ele é empregado para responder segmentos para alguma porta de destino não alocada.

\section{Controle de Congestionamento}

Protocolos como o TCP fazem com que conexões entre hosts através de links não confiáveis sejam oferecidas às aplicações como conexões lógicas entre hosts, com garantias de entrega confiável.
Assim, os mecanismos já citados da camada de transporte visam lidar principalmente com a perda de pacotes.
Esta perda está associada principalmente ao descarte de pacotes que é realizado pelos roteadores do core da rede, quando a taxa de chegada de dados é superior à taxa em que tais pacotes podem ser transmitidos pelo enlace de saída.

Assim, os mecanismos de entrega confiável empregam retransmissões para tratar de sintomas do congestionamento da rede, 
mas não tratam as causas de tais perdas.
E tais causas normalmente estão associadas a muitos processos e/ou hosts que enviam pacotes à uma taxa mais alta que a suportada pelos enlaces.

As consequências destas inundações são diretamente percebidas pelas aplicações, que notam uma degradação, um subuso da rede.
Isto porque as camadas inferiores não lidam com os pacotes como dados, como algo que tem semântica definida, ou seja, não distinguem um envio de uma retransmissão.

É interessante notar que mesmo em cenários irreais, o congestionamento ocorreria. 
Ou seja, mesmo com buffers infinitos, havendo duas conexões que compartilham um mesmo enlace com taxa $R$ haverá perda de eficiência se estas duas conexões estiverem usando, conjuntamente, boa parte ou toda a largura da rede.

Neste caso, isto se deve a um dos mecanismos usados para inferir perdas, que é o RTT acima do esperado.
Quando um roteador começa a operar com taxas de entrada que se aproximem à sua capacidade de saída o tempo de resposta cresce exponencialmente.

Isto faz com os temporizadores estourem e pacotes (que serão entregues, pois não há perdas) sejam desnecessariamente retransmitidos, fazendo com que parte do esforço de transmissão seja desperdiçado com pacotes duplicados, que serão descartados no destino.
Assim, neste cenário irrealístico, a taxa efetiva de transmissão das várias conexões será inferior ao esperado.

Como na realidade os buffers são finitos, tem-se perdas quando a fila de saída do roteador está cheia.
Assim alguns pacotes chegam e outros não chegam ao destino, mas, visto o grande delay, a camada de transporte não saberá distinguí-los, reenviando todos.

Isto pode ser ainda mais complicado se se supõe que há vários roteadores no caminho do pacote, todos sobrecarregados.
Neste caso, mesmo que um pacote não seja descartado em algum deles, há grande probabilidade dele ser descartado em outros intermediários,
fazendo com que o throupughput efetivo tenda a zero quando as taxas de envio somadas forem próximas à capacidade da rede.

Assim, o congestionamento deve ser evitado ou tratado, sob risco de se ter uma estagnação na comunicação entre processos da rede.
Mostra-se a seguir as principais abordagens empregáveis.

\subsection{Network-assisted}

Nesta abordagem a camada de rede (ou seja, os roteadores) provêm feedback explícito sobre o tráfego de rede.
Isto pode ser feito através da sinalização (ativação de algum bit no cabeçalho de rede) nos pacotes que trafegam em um ambiente congestionado, 
através de mensagens especiais enviadas pelos roteadores aos emissores e/ou 
através de mensagens especiais trocadas pelos hosts finais e com campos alterados durante o seu percurso na rede.

Um exemplo desta abordagem é o mecanismo \emph{Avaliable Bit Rate} (\emph{ABR}) empregado nas redes \emph{ATM}.
Nele, além de pacotes de dados há pacotes especiais \emph{Resource Management Cells} ou \emph{RM cells} que trafegam junto aos pacotes comuns mas não contém carga útil.

Há três abordagens de sinalização de congestionamento.
Na primeira os roteadores modificam o bit \emph{EFCI} de pacotes comuns que trafeguem em ambientes congestionados.
Ao receber um pacote todo host checa este bit e achando-o ativado, envia uma célula RM com bit \emph{Congestion Indication} ativado para o emissor.

Além destes avisos de emergência, tem-se as células RM que trafegam na rede, interpostas entre conjunto de pacotes comuns.
Elas possuem um campo de \emph{taxa explícita}, que pode ser decrementado pelos roteadores, fazendo com que os hosts finais saibam a taxa mais alta possível na rede.
Além deles tem-se o CI já citado e o \emph{No Increase} que significa que tem-se risco de congestionamento se a taxa for incrementada.

Com base nos dados obtidos do tráfego destas células RM pela rede, calcula-se a taxa máxima de envio nos hosts finais e tem-se um mecanismo eficaz para evitar e tratar do congestionamento.

\subsection{End-to-end}

Quando a camada de rede não provê feedback explícito do tráfego, a camada de transporte deve inferir o estado da rede através do comportamento do tráfego fim-a-fim.
Este é o caso do protocolo IP, o que faz com que o TCP, empregando as taxas de perda e a quantidade de ACKs duplicados, tente inferir se há congestionamento.

Identificando possíveis situações do gênero, o TCP deve reduzir sua taxa de envio de pacotes, o que é feito limitando o tamanho da janela de transmissão,
que já é limitada também pelo controle de fluxo.
Ao mesmo tempo, estando a rede livre, espera-se que o limite de tamanho da janela não seja mais estabelecido pelo congestionamento (que não há),
mas sim pelo controle de fluxo.

Assim, o TCP age da seguinte forma.
Quando um segmento é perdido (ou seja, há um timeout ou três ACKs duplicados) a taxa de transmissão deve cair.
Quando a confirmação de um segmento é recebida, a rede entregou o pacote e a taxa de transmissão pode ser aumentada.
Mas até quando ela pode ser aumentada? No caso do TCP, ela é aumentada até que haja perdas, ou seja, até que se tenha um alerta de possível congestionamento, e, neste caso, ela deve ser reduzida (normalmente de forma brusca).

\section{Controle de Congestionamento TCP}

Consiste em manter a taxa de envio em dois estágios distintos:

\paragraph{Partida lenta} A conexão é normalmente iniciada com janela mínima de 1 \emph{MSS}. A partir daí, a cada ACK recebido, a janela é incrementada. Assim, a cada RTT, a janela é duplicada. Este crescimento se dá exponencialmente até que se chegue a um \emph{threshold} pré-determinado.

\paragraph{Congestion Avoidance} A partir do \emph{threshold}, o crescimento da janela passa a ser linear com os RTTs. Assim, a cada RTT incrementa-se o tamanho da janela em 1 \emph{MSS}

\paragraph{Fast Recovery} Recebendo-se um \emph{ACK}, vai-se para o \emph{congestion avoidance}. Esta fase é recomendada e o TCP Tahoe não implementa ela.

\paragraph{Timeout} Em qualquer destes estágios, se há um timeout para algum pacote, a janela é reduzida a \emph{1 MSS} e volta-se à \emph{partida lenta}. 
O \emph{threshold} é configurado para a metade do valor atual da janela.

\paragraph{Três ACKs duplicados} O \emph{threshold} é configurado para a metade do valor atual da janela. No TCP Reno a janela é reduzida para o novo valor do \emph{threshold} e vai-se para o \emph{fast recovery}. No Tahoe, o comportamento é igual a de um timeout.

Por suas características este mecanismo tem-se uma adição incremental e um descrescimento multiplicativo (\emph{AIMD}), 
levando a um comportamento serrilhado.
Ignorando a partida lenta, o crescimento é linear até passar do limite e fazer com que algum segmento seja perdido e receba-se o terceiro ACK.
Aí a janela é dividida pela metade (o que pode ser conservador) e continua-se crescendo-a linearmente.

\subsection{Justiça}

Além de evitar que a rede seja inundada, o controle de congestionamento teria como objetivo também distribuir igualitariamente dentre as várias conexões a banda disponível.
Isto não ocorre exatamente com o TCP, visto que RTTs maiores tem crescimento mais lento na janela de transmissão e assim são prejudicados.

Porém, o mecanismo per si tende a levar conexões com RTTs próximos a, após certo tempo, dividirem a banda igualitariamente.
É interessante notar que a justiça é entre conexões e não entre processos. Se um mesmo processo fizer múltiplas conexões, ele ocupará maior parte da banda, provavelmente.

Vale notar que o UDP não tem controle de banda e, assim, pode ``tomar'' toda banda de conexões TCP que, vendo indícios de congestionamento vão reduzir a taxa de transmissão.
É bom notar que não ter restrições de banda é uma vantagem do UDP, mas que, normalmente, a maior parte do tráfego UDP é bloqueado nos firewalls.

\subsection{Adendos ao TCP}

\paragraph{TCP Vegas} Calcula-se a diferença \emph{vazão esperada - (tamanho da janela/minimo RTT)}. 
Se ela for superior a um $\beta$, há um acréscimo linear da janela.
Se for inferior a um $\alpha$, há um decréscimo linear da janela.
O congestionamento é inferido a partir do RTT, não pelas perdas.
Assim, as perdas são mais raras, o que faz com que a reação (o fast recovery) para ACK duplicados seja imediato (não a cada três).
O crescimento da janela é exponencial a cada RTT não incrementada a cada ACK.
O resultado é um tamanho de janela mais estável e convergente.

\paragraph{TCP Sack} Opção negociável onde o receptor pode comunicar quais segmentos faltam (confirmação seletiva). 
A retransmissão é condicionada a não ter-se em trânsito mais segmentos que o tamanho da janela.
Assim, evita-se retransmissões desnecessárias.

\paragraph{TCP Fack} Modifica-se o TCP Sack de forma de manter o número de segmentos em trânsito e não confirmados menores que a janela.

\paragraph{TCP New Reno} Modificação do TCP Reno em que no \emph{fast recovery} cada ACK duplicado aumenta em 1 MSS o tamanho da janela, 
sendo encerrado com um ACK válido.

\paragraph{Stream Control Transmission Protocol (SCTP)} 
Alternativa ao TCP com suporte a novas funcionalidades.
As principais são o \emph{multi-streaming} e \emph{multi-homing}, que permitem que uma mesma conexão contenha múltiplos fluxos e que os dados usem endereços e caminhos diferentes.
Os dados são divididos em vários chunks que são reunidos no destino e entregue as aplicações. 
Além do mais, os chunks podem ter tanto dados como sinalizações e o estabelecimento da conexão evita o \emph{syn flood}, com 4 passos de comunicação.
A entrega pode ser ordenada ou não, sendo indicada para dados multimídia também.

\paragraph{Opções para o UDP} Há o \emph{UDP Lite} e o \emph{Datagram Congestion Control Protocol} que trazem o controle de congestionamento para o UDP, 
possibilitando usar a semântica simples do UDP para conexões na Internet (para multimidia, por exemplo).

\subsection{TCP para redes com alto produto banda-atraso}

O controle de congestionamento se dá através de perdas e o crescimento da janela por RTT.
Se o RTT é alto a janela cresce muito lentamente (mesmo havendo largura de banda).
Se a banda é bem larga (redes de alta velocidade) a janela máxima é atingida após muito tempo, com taxas irrealisticamente baixas de erros.

As abordagens para redes de alta velocidade é obter crescimento mais rápido e implementar técnicas de crescimento baseado em atraso ou mistas.

Quando tem-se muito atraso, como nos enlaces por satélite, emprega-se soluções genéricas que empregam estimativas de banda passante e possibilitam um crescimento mais rápido da janela, não dependente completamente do RTT.
Outra opção é segmentar a conexão, empregando um protocolo comum nos enlaces normais e um protocolo específico nos enlaces via satélite.

\subsection{TCP para redes sem fio}

Os problemas estão associados a alta taxa de erros inerente do meio, que serão tratadas como falso indício de congestionamento.
Outra questão são as perdas de sinal e os handoffs, que são desconexões e caem no mesmo problema.

Uma das linhas de solução é a segmentação da conexão entre a rede sem fio e rede normal.
A escolha a ser feita é a capacidade de tratamento de erro + suporte a handoff contra o tamanho dos buffers que as estações bases terão de ter (para mascarar as perdas).

Outra linha mantém a conexão fim-a-fim e tenta discriminar o erro do enlace de rede das perdas por congestionamento.
Pode-se usar outros modelos de detecção de erros (como o jitter), congelar os relógios quando há erro local ou permissões para crescimento mais rápido da janela, mesmo com os erros.
Pode-se também mascarar as perdas do ambiente também.
Outra linha viola a autonomia fim-a-fim e tem-se notificações entre emissor e receptores.

Para o ambiente \emph{ad-hoc} o grande problema é a perda de rotas e conexões.
Neste caso não pode-se abstrair os problemas da camada de rede tratando-os como erros.
Assim, viola-se a independência das camadas se se quiser usar TCP.
